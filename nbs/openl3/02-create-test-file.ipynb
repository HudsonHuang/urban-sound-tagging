{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import openl3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sai/anaconda3/envs/py37/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/sai/anaconda3/envs/py37/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/sai/anaconda3/envs/py37/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1702: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/sai/anaconda3/envs/py37/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/sai/anaconda3/envs/py37/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/sai/anaconda3/envs/py37/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/sai/anaconda3/envs/py37/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = openl3.models.load_embedding_model(input_repr=\"mel128\", content_type=\"env\", embedding_size=6144)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 1, 48000)          0         \n",
      "_________________________________________________________________\n",
      "melspectrogram_1 (Melspectro (None, 128, 199, 1)       4329600   \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 128, 199, 1)       4         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 128, 199, 64)      640       \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 128, 199, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 128, 199, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 128, 199, 64)      36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 128, 199, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 128, 199, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 64, 99, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 64, 99, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 64, 99, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 64, 99, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 64, 99, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 64, 99, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 64, 99, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 32, 49, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 32, 49, 256)       295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 32, 49, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 32, 49, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 32, 49, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 32, 49, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 32, 49, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 16, 24, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 16, 24, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 16, 24, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 16, 24, 512)       0         \n",
      "_________________________________________________________________\n",
      "audio_embedding_layer (Conv2 (None, 16, 24, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 4, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 6144)              0         \n",
      "=================================================================\n",
      "Total params: 9,019,460\n",
      "Trainable params: 4,687,042\n",
      "Non-trainable params: 4,332,418\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Model, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = model.get_layer('input_1').input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "oups = [\n",
    "    model.get_layer('melspectrogram_1').output,\n",
    "    model.get_layer('batch_normalization_1').output,\n",
    "    model.get_layer('conv2d_1').output,\n",
    "    model.get_layer('batch_normalization_2').output,\n",
    "    model.get_layer('activation_1').output,\n",
    "    model.get_layer('conv2d_2').output,\n",
    "    model.get_layer('batch_normalization_3').output,\n",
    "    model.get_layer('activation_2').output,\n",
    "    model.get_layer('conv2d_3').output,\n",
    "    model.get_layer('batch_normalization_4').output,\n",
    "    #--------\n",
    "    model.get_layer('batch_normalization_8').output,\n",
    "    model.get_layer('activation_7').output,\n",
    "    model.get_layer('audio_embedding_layer').output,\n",
    "    model.get_layer('max_pooling2d_4').output,\n",
    "    model.get_layer('flatten_1').output,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Model(inputs=[inp], outputs=oups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "file_list = sorted(glob('../../data/train/*.wav') + glob('../../data/validate/*.wav'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = file_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'01_000006.wav'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.path.basename(file_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "audio_np, sr = librosa.load(\n",
    "        file_list[0],\n",
    "        sr=48000) # 48000 is the required sr by openl3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_SR = 48000\n",
    "hop_size=0.1\n",
    "hop_len = int(hop_size * TARGET_SR)\n",
    "frame_len = TARGET_SR\n",
    "def _pad_audio(audio, frame_len, hop_len):\n",
    "    \"\"\"Pad audio if necessary so that all samples are processed\"\"\"\n",
    "    audio_len = audio.size\n",
    "    if audio_len < frame_len:\n",
    "        pad_length = frame_len - audio_len\n",
    "    else:\n",
    "        pad_length = int(np.ceil((audio_len - frame_len)/float(hop_len))) * hop_len \\\n",
    "                     - (audio_len - frame_len)\n",
    "\n",
    "    if pad_length > 0:\n",
    "        audio = np.pad(audio, (0, pad_length), mode='constant', constant_values=0)\n",
    "\n",
    "    return audio\n",
    "\n",
    "audio = _pad_audio(audio_np, frame_len, hop_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_frames = 1 + int((len(audio) - frame_len) / float(hop_len))\n",
    "x = np.lib.stride_tricks.as_strided(audio, shape=(frame_len, n_frames),\n",
    "        strides=(audio.itemsize, hop_len * audio.itemsize)).T\n",
    "# Add a channel dimension\n",
    "x = x.reshape((x.shape[0], 1, x.shape[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(92, 1, 48000)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 4s 44ms/step\n"
     ]
    }
   ],
   "source": [
    "ans = model2.predict(x, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test.pkl', 'wb') as f:\n",
    "    pickle.dump(ans, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
