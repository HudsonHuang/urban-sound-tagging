{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "__weights_dict = dict()\n",
    "\n",
    "def load_weights(weight_file):\n",
    "    if weight_file == None:\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        weights_dict = np.load(weight_file).item()\n",
    "    except:\n",
    "        weights_dict = np.load(weight_file, encoding='bytes').item()\n",
    "\n",
    "    return weights_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KitModel(nn.Module):\n",
    "\n",
    "    \n",
    "    def __init__(self, weight_file):\n",
    "        super(KitModel, self).__init__()\n",
    "        global __weights_dict\n",
    "        __weights_dict = load_weights(weight_file)\n",
    "\n",
    "        self.batch_normalization_1 = self.__batch_normalization(2, 'batch_normalization_1', num_features=1, eps=0.0010000000474974513, momentum=0.0)\n",
    "        self.conv2d_1 = self.__conv(2, name='conv2d_1', in_channels=1, out_channels=64, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=True)\n",
    "        self.batch_normalization_2 = self.__batch_normalization(2, 'batch_normalization_2', num_features=64, eps=0.0010000000474974513, momentum=0.0)\n",
    "        self.conv2d_2 = self.__conv(2, name='conv2d_2', in_channels=64, out_channels=64, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=True)\n",
    "        self.batch_normalization_3 = self.__batch_normalization(2, 'batch_normalization_3', num_features=64, eps=0.0010000000474974513, momentum=0.0)\n",
    "        self.conv2d_3 = self.__conv(2, name='conv2d_3', in_channels=64, out_channels=128, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=True)\n",
    "        self.batch_normalization_4 = self.__batch_normalization(2, 'batch_normalization_4', num_features=128, eps=0.0010000000474974513, momentum=0.0)\n",
    "        self.conv2d_4 = self.__conv(2, name='conv2d_4', in_channels=128, out_channels=128, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=True)\n",
    "        self.batch_normalization_5 = self.__batch_normalization(2, 'batch_normalization_5', num_features=128, eps=0.0010000000474974513, momentum=0.0)\n",
    "        self.conv2d_5 = self.__conv(2, name='conv2d_5', in_channels=128, out_channels=256, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=True)\n",
    "        self.batch_normalization_6 = self.__batch_normalization(2, 'batch_normalization_6', num_features=256, eps=0.0010000000474974513, momentum=0.0)\n",
    "        self.conv2d_6 = self.__conv(2, name='conv2d_6', in_channels=256, out_channels=256, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=True)\n",
    "        self.batch_normalization_7 = self.__batch_normalization(2, 'batch_normalization_7', num_features=256, eps=0.0010000000474974513, momentum=0.0)\n",
    "        self.conv2d_7 = self.__conv(2, name='conv2d_7', in_channels=256, out_channels=512, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=True)\n",
    "        self.batch_normalization_8 = self.__batch_normalization(2, 'batch_normalization_8', num_features=512, eps=0.0010000000474974513, momentum=0.0)\n",
    "        self.audio_embedding_layer = self.__conv(2, name='audio_embedding_layer', in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_normalization_1 = self.batch_normalization_1(x)\n",
    "        conv2d_1_pad    = F.pad(batch_normalization_1, (1, 1, 1, 1))\n",
    "        conv2d_1        = self.conv2d_1(conv2d_1_pad)\n",
    "        batch_normalization_2 = self.batch_normalization_2(conv2d_1)\n",
    "        activation_1    = F.relu(batch_normalization_2)\n",
    "        conv2d_2_pad    = F.pad(activation_1, (1, 1, 1, 1))\n",
    "        conv2d_2        = self.conv2d_2(conv2d_2_pad)\n",
    "        batch_normalization_3 = self.batch_normalization_3(conv2d_2)\n",
    "        activation_2    = F.relu(batch_normalization_3)\n",
    "        max_pooling2d_1 = F.max_pool2d(activation_2, kernel_size=(2, 2), stride=(2, 2), padding=0, ceil_mode=False)\n",
    "        conv2d_3_pad    = F.pad(max_pooling2d_1, (1, 1, 1, 1))\n",
    "        conv2d_3        = self.conv2d_3(conv2d_3_pad)\n",
    "        batch_normalization_4 = self.batch_normalization_4(conv2d_3)\n",
    "        activation_3    = F.relu(batch_normalization_4)\n",
    "        conv2d_4_pad    = F.pad(activation_3, (1, 1, 1, 1))\n",
    "        conv2d_4        = self.conv2d_4(conv2d_4_pad)\n",
    "        batch_normalization_5 = self.batch_normalization_5(conv2d_4)\n",
    "        activation_4    = F.relu(batch_normalization_5)\n",
    "        max_pooling2d_2 = F.max_pool2d(activation_4, kernel_size=(2, 2), stride=(2, 2), padding=0, ceil_mode=False)\n",
    "        conv2d_5_pad    = F.pad(max_pooling2d_2, (1, 1, 1, 1))\n",
    "        conv2d_5        = self.conv2d_5(conv2d_5_pad)\n",
    "        batch_normalization_6 = self.batch_normalization_6(conv2d_5)\n",
    "        activation_5    = F.relu(batch_normalization_6)\n",
    "        conv2d_6_pad    = F.pad(activation_5, (1, 1, 1, 1))\n",
    "        conv2d_6        = self.conv2d_6(conv2d_6_pad)\n",
    "        batch_normalization_7 = self.batch_normalization_7(conv2d_6)\n",
    "        activation_6    = F.relu(batch_normalization_7)\n",
    "        max_pooling2d_3 = F.max_pool2d(activation_6, kernel_size=(2, 2), stride=(2, 2), padding=0, ceil_mode=False)\n",
    "        conv2d_7_pad    = F.pad(max_pooling2d_3, (1, 1, 1, 1))\n",
    "        conv2d_7        = self.conv2d_7(conv2d_7_pad)\n",
    "        batch_normalization_8 = self.batch_normalization_8(conv2d_7)\n",
    "        activation_7    = F.relu(batch_normalization_8)\n",
    "        audio_embedding_layer_pad = F.pad(activation_7, (1, 1, 1, 1))\n",
    "        audio_embedding_layer = self.audio_embedding_layer(audio_embedding_layer_pad)\n",
    "        max_pooling2d_4 = F.max_pool2d(audio_embedding_layer, kernel_size=(4, 8), stride=(4, 8), padding=0, ceil_mode=False)\n",
    "        flatten_1       = max_pooling2d_4.view(max_pooling2d_4.size(0), -1)\n",
    "        return max_pooling2d_4, flatten_1\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def __batch_normalization(dim, name, **kwargs):\n",
    "        if   dim == 0 or dim == 1:  layer = nn.BatchNorm1d(**kwargs)\n",
    "        elif dim == 2:  layer = nn.BatchNorm2d(**kwargs)\n",
    "        elif dim == 3:  layer = nn.BatchNorm3d(**kwargs)\n",
    "        else:           raise NotImplementedError()\n",
    "\n",
    "        if 'scale' in __weights_dict[name]:\n",
    "            layer.state_dict()['weight'].copy_(torch.from_numpy(__weights_dict[name]['scale']))\n",
    "        else:\n",
    "            layer.weight.data.fill_(1)\n",
    "\n",
    "        if 'bias' in __weights_dict[name]:\n",
    "            layer.state_dict()['bias'].copy_(torch.from_numpy(__weights_dict[name]['bias']))\n",
    "        else:\n",
    "            layer.bias.data.fill_(0)\n",
    "\n",
    "        layer.state_dict()['running_mean'].copy_(torch.from_numpy(__weights_dict[name]['mean']))\n",
    "        layer.state_dict()['running_var'].copy_(torch.from_numpy(__weights_dict[name]['var']))\n",
    "        return layer\n",
    "\n",
    "    @staticmethod\n",
    "    def __conv(dim, name, **kwargs):\n",
    "        if   dim == 1:  layer = nn.Conv1d(**kwargs)\n",
    "        elif dim == 2:  layer = nn.Conv2d(**kwargs)\n",
    "        elif dim == 3:  layer = nn.Conv3d(**kwargs)\n",
    "        else:           raise NotImplementedError()\n",
    "\n",
    "        layer.state_dict()['weight'].copy_(torch.from_numpy(__weights_dict[name]['weights']))\n",
    "        if 'bias' in __weights_dict[name]:\n",
    "            layer.state_dict()['bias'].copy_(torch.from_numpy(__weights_dict[name]['bias']))\n",
    "        return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KitModel('./openl3_no_mel_layer_pytorch_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "with open('test.pkl', 'rb') as f:\n",
    "    test_data = pickle.load(f)\n",
    "len(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.set_grad_enabled(False):\n",
    "    model = model.eval()\n",
    "    output_got, _ = model(\n",
    "        torch.Tensor(test_data[0].swapaxes(2, 3).swapaxes(1, 2))\n",
    "    )\n",
    "    output_got = output_got.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_needed = test_data[-2].swapaxes(2, 3).swapaxes(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((92, 512, 4, 3), (92, 512, 4, 3))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_needed.shape, output_got.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fd982648e10>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(output_needed[0, :, 0, 0], output_got[0, :, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
