{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "__weights_dict = dict()\n",
    "\n",
    "def load_weights(weight_file):\n",
    "    if weight_file == None:\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        weights_dict = np.load(weight_file).item()\n",
    "    except:\n",
    "        weights_dict = np.load(weight_file, encoding='bytes').item()\n",
    "\n",
    "    return weights_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KitModel(nn.Module):\n",
    "\n",
    "    \n",
    "    def __init__(self, weight_file):\n",
    "        super(KitModel, self).__init__()\n",
    "        global __weights_dict\n",
    "        __weights_dict = load_weights(weight_file)\n",
    "\n",
    "        self.batch_normalization_1 = self.__batch_normalization(2, 'batch_normalization_1', num_features=1, eps=0.001, momentum=0.0)\n",
    "        self.conv2d_1 = self.__conv(2, name='conv2d_1', in_channels=1, out_channels=64, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=True)\n",
    "        self.batch_normalization_2 = self.__batch_normalization(2, 'batch_normalization_2', num_features=64, eps=0.001, momentum=0.0)\n",
    "        self.conv2d_2 = self.__conv(2, name='conv2d_2', in_channels=64, out_channels=64, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=True)\n",
    "        self.batch_normalization_3 = self.__batch_normalization(2, 'batch_normalization_3', num_features=64, eps=0.001, momentum=0.0)\n",
    "        self.conv2d_3 = self.__conv(2, name='conv2d_3', in_channels=64, out_channels=128, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=True)\n",
    "        self.batch_normalization_4 = self.__batch_normalization(2, 'batch_normalization_4', num_features=128, eps=0.001, momentum=0.0)\n",
    "        self.conv2d_4 = self.__conv(2, name='conv2d_4', in_channels=128, out_channels=128, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=True)\n",
    "        self.batch_normalization_5 = self.__batch_normalization(2, 'batch_normalization_5', num_features=128, eps=0.001, momentum=0.0)\n",
    "        self.conv2d_5 = self.__conv(2, name='conv2d_5', in_channels=128, out_channels=256, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=True)\n",
    "        self.batch_normalization_6 = self.__batch_normalization(2, 'batch_normalization_6', num_features=256, eps=0.001, momentum=0.0)\n",
    "        self.conv2d_6 = self.__conv(2, name='conv2d_6', in_channels=256, out_channels=256, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=True)\n",
    "        self.batch_normalization_7 = self.__batch_normalization(2, 'batch_normalization_7', num_features=256, eps=0.001, momentum=0.0)\n",
    "        self.conv2d_7 = self.__conv(2, name='conv2d_7', in_channels=256, out_channels=512, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=True)\n",
    "        self.batch_normalization_8 = self.__batch_normalization(2, 'batch_normalization_8', num_features=512, eps=0.001, momentum=0.0)\n",
    "        self.audio_embedding_layer = self.__conv(2, name='audio_embedding_layer', in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_normalization_1 = self.batch_normalization_1(x)\n",
    "        conv2d_1_pad    = F.pad(batch_normalization_1, (1, 1, 1, 1))\n",
    "        conv2d_1        = self.conv2d_1(conv2d_1_pad)\n",
    "        batch_normalization_2 = self.batch_normalization_2(conv2d_1)\n",
    "        activation_1    = F.relu(batch_normalization_2)\n",
    "        conv2d_2_pad    = F.pad(activation_1, (1, 1, 1, 1))\n",
    "        conv2d_2        = self.conv2d_2(conv2d_2_pad)\n",
    "        batch_normalization_3 = self.batch_normalization_3(conv2d_2)\n",
    "        activation_2    = F.relu(batch_normalization_3)\n",
    "        max_pooling2d_1 = F.max_pool2d(activation_2, kernel_size=(2, 2), stride=(2, 2), padding=0, ceil_mode=False)\n",
    "        conv2d_3_pad    = F.pad(max_pooling2d_1, (1, 1, 1, 1))\n",
    "        conv2d_3        = self.conv2d_3(conv2d_3_pad)\n",
    "        batch_normalization_4 = self.batch_normalization_4(conv2d_3)\n",
    "        activation_3    = F.relu(batch_normalization_4)\n",
    "        conv2d_4_pad    = F.pad(activation_3, (1, 1, 1, 1))\n",
    "        conv2d_4        = self.conv2d_4(conv2d_4_pad)\n",
    "        batch_normalization_5 = self.batch_normalization_5(conv2d_4)\n",
    "        activation_4    = F.relu(batch_normalization_5)\n",
    "        max_pooling2d_2 = F.max_pool2d(activation_4, kernel_size=(2, 2), stride=(2, 2), padding=0, ceil_mode=False)\n",
    "        conv2d_5_pad    = F.pad(max_pooling2d_2, (1, 1, 1, 1))\n",
    "        conv2d_5        = self.conv2d_5(conv2d_5_pad)\n",
    "        batch_normalization_6 = self.batch_normalization_6(conv2d_5)\n",
    "        activation_5    = F.relu(batch_normalization_6)\n",
    "        conv2d_6_pad    = F.pad(activation_5, (1, 1, 1, 1))\n",
    "        conv2d_6        = self.conv2d_6(conv2d_6_pad)\n",
    "        batch_normalization_7 = self.batch_normalization_7(conv2d_6)\n",
    "        activation_6    = F.relu(batch_normalization_7)\n",
    "        max_pooling2d_3 = F.max_pool2d(activation_6, kernel_size=(2, 2), stride=(2, 2), padding=0, ceil_mode=False)\n",
    "        conv2d_7_pad    = F.pad(max_pooling2d_3, (1, 1, 1, 1))\n",
    "        conv2d_7        = self.conv2d_7(conv2d_7_pad)\n",
    "        batch_normalization_8 = self.batch_normalization_8(conv2d_7)\n",
    "        activation_7    = F.relu(batch_normalization_8)\n",
    "        audio_embedding_layer_pad = F.pad(activation_7, (1, 1, 1, 1))\n",
    "        audio_embedding_layer = self.audio_embedding_layer(audio_embedding_layer_pad)\n",
    "        max_pooling2d_4 = F.max_pool2d(audio_embedding_layer, kernel_size=(4, 8), stride=(4, 8), padding=0, ceil_mode=False)\n",
    "        flatten_1       = max_pooling2d_4.view(max_pooling2d_4.size(0), -1)\n",
    "        return flatten_1\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def __batch_normalization(dim, name, **kwargs):\n",
    "        if   dim == 0 or dim == 1:  layer = nn.BatchNorm1d(**kwargs)\n",
    "        elif dim == 2:  layer = nn.BatchNorm2d(**kwargs)\n",
    "        elif dim == 3:  layer = nn.BatchNorm3d(**kwargs)\n",
    "        else:           raise NotImplementedError()\n",
    "\n",
    "        if 'scale' in __weights_dict[name]:\n",
    "            layer.state_dict()['weight'].copy_(torch.from_numpy(__weights_dict[name]['scale']))\n",
    "        else:\n",
    "            layer.weight.data.fill_(1)\n",
    "\n",
    "        if 'bias' in __weights_dict[name]:\n",
    "            layer.state_dict()['bias'].copy_(torch.from_numpy(__weights_dict[name]['bias']))\n",
    "        else:\n",
    "            layer.bias.data.fill_(0)\n",
    "\n",
    "        layer.state_dict()['running_mean'].copy_(torch.from_numpy(__weights_dict[name]['mean']))\n",
    "        layer.state_dict()['running_var'].copy_(torch.from_numpy(__weights_dict[name]['var']))\n",
    "        return layer\n",
    "\n",
    "    @staticmethod\n",
    "    def __conv(dim, name, **kwargs):\n",
    "        if   dim == 1:  layer = nn.Conv1d(**kwargs)\n",
    "        elif dim == 2:  layer = nn.Conv2d(**kwargs)\n",
    "        elif dim == 3:  layer = nn.Conv3d(**kwargs)\n",
    "        else:           raise NotImplementedError()\n",
    "\n",
    "        layer.state_dict()['weight'].copy_(torch.from_numpy(__weights_dict[name]['weights']))\n",
    "        if 'bias' in __weights_dict[name]:\n",
    "            layer.state_dict()['bias'].copy_(torch.from_numpy(__weights_dict[name]['bias']))\n",
    "        return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KitModel('./openl3_no_mel_layer_pytorch_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel = np.load('test_mel.npy')\n",
    "keras_embed = np.load('test_embed.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(92, 128, 199, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(92, 1, 128, 199)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mel = mel.swapaxes(2, 3).swapaxes(1,2)\n",
    "mel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_embed = model(torch.Tensor(mel)).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((92, 6144), (92, 6144))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_embed.shape, pytorch_embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01407197, -0.47005564,  1.7490387 , ...,  1.0194218 ,\n",
       "         2.2061288 ,  1.4309345 ],\n",
       "       [ 0.2527672 , -0.17458485,  1.6850142 , ...,  1.0417615 ,\n",
       "         2.3111584 ,  1.4627569 ],\n",
       "       [-0.08403763, -0.24511683,  1.353284  , ...,  1.0111903 ,\n",
       "         2.4722123 ,  1.556586  ],\n",
       "       ...,\n",
       "       [ 0.28062472, -0.14530571,  1.7931194 , ...,  1.0891767 ,\n",
       "         2.1539266 ,  1.3076913 ],\n",
       "       [ 0.26866186, -0.149735  ,  1.5948242 , ...,  1.2059139 ,\n",
       "         2.1042416 ,  1.2843417 ],\n",
       "       [ 0.27962628, -0.15925293,  1.492332  , ...,  1.2207866 ,\n",
       "         2.4765594 ,  1.3827238 ]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.0289554 ,  0.38963738,  0.6501105 , ...,  1.1759684 ,\n",
       "         1.2946868 ,  1.2517651 ],\n",
       "       [ 0.07351127,  0.5848462 ,  0.6674768 , ...,  1.1070098 ,\n",
       "         1.2642834 ,  1.2949477 ],\n",
       "       [ 0.05469802,  0.70704186,  0.58006215, ...,  1.2790492 ,\n",
       "         1.1422132 ,  1.3535105 ],\n",
       "       ...,\n",
       "       [ 0.5951878 ,  0.7266215 ,  0.52566427, ...,  1.6848669 ,\n",
       "         1.3164846 ,  1.108053  ],\n",
       "       [ 0.6399651 ,  0.7508493 ,  0.4930579 , ...,  1.4478065 ,\n",
       "         1.0835762 ,  1.0180122 ],\n",
       "       [ 0.6606014 ,  0.7299656 ,  0.40768704, ...,  1.5421507 ,\n",
       "         1.090433  ,  2.1529472 ]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytorch_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01407197, -0.47005564,  1.7490387 , ...,  1.0194218 ,\n",
       "        2.2061288 ,  1.4309345 ], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_embed[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.0289554 ,  0.38963738,  0.6501105 , ...,  1.1759684 ,\n",
       "        1.2946868 ,  1.2517651 ], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytorch_embed[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
