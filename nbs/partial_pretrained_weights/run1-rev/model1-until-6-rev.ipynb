{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "papermill": {
     "duration": 0.040837,
     "end_time": "2019-10-20T14:11:06.970583",
     "exception": false,
     "start_time": "2019-10-20T14:11:06.929746",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "until_x = 6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "papermill": {
     "duration": 1.274926,
     "end_time": "2019-10-20T14:11:08.266952",
     "exception": false,
     "start_time": "2019-10-20T14:11:06.992026",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from RandomErasing import RandomErasing\n",
    "\n",
    "import torchvision.models\n",
    "from torchvision import transforms\n",
    "\n",
    "from albumentations import Compose, ShiftScaleRotate, GridDistortion\n",
    "from albumentations.pytorch import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "papermill": {
     "duration": 0.058512,
     "end_time": "2019-10-20T14:11:08.352672",
     "exception": false,
     "start_time": "2019-10-20T14:11:08.294160",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_data(df, unknown_to_known):\n",
    "    df = df.reset_index()\n",
    "    df['slno'] = df.assign(slno=1).groupby('audio_filename')['slno'].cumsum()\n",
    "    df.set_index(['audio_filename', 'slno'], inplace=True)\n",
    "\n",
    "    df_unknown = df.copy().loc[:, list(unknown_to_known.keys())]\n",
    "    df.drop(columns=list(unknown_to_known.keys()), inplace=True)\n",
    "\n",
    "    y_mask = df.copy()\n",
    "    y_mask.loc[:, :] = 1\n",
    "    for unknown, known in unknown_to_known.items():\n",
    "        y_mask.loc[\n",
    "            df_unknown[unknown] > 0.5,\n",
    "            known\n",
    "        ] = 0\n",
    "\n",
    "    df = df.swaplevel(i=1, j=0, axis=0).sort_index()\n",
    "\n",
    "    y_mask = y_mask.swaplevel(i=1, j=0, axis=0).sort_index()\n",
    "\n",
    "    y = np.concatenate([\n",
    "        df.loc[[1], :].values[..., np.newaxis],\n",
    "        df.loc[[2], :].values[..., np.newaxis],\n",
    "        df.loc[[3], :].values[..., np.newaxis]\n",
    "    ], axis=2)\n",
    "\n",
    "    y_mask = np.concatenate([\n",
    "        y_mask.loc[[1], :].values[..., np.newaxis],\n",
    "        y_mask.loc[[2], :].values[..., np.newaxis],\n",
    "        y_mask.loc[[3], :].values[..., np.newaxis]\n",
    "    ], axis=2)\n",
    "\n",
    "    X = np.concatenate([\n",
    "        np.expand_dims(np.load('../../data/logmelspec/{}.npy'.format(x)).T[:635, :], axis=0)\n",
    "        for x in df.loc[[1], :].reset_index(1).audio_filename.tolist()])\n",
    "    X = np.expand_dims(X, axis=1)\n",
    "\n",
    "    return X, y, y_mask\n",
    "\n",
    "\n",
    "random_erasing = RandomErasing()\n",
    "\n",
    "\n",
    "class AudioDataset(Dataset):\n",
    "\n",
    "    def __init__(self, X, y, weights, transform=None):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.weights = weights\n",
    "        self.transform = transform\n",
    "        self.pil = transforms.ToPILImage()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.X[idx, ...]\n",
    "\n",
    "        if self.transform:\n",
    "            # min-max transformation\n",
    "            this_min = sample.min()\n",
    "            this_max = sample.max()\n",
    "            sample = (sample - this_min) / (this_max - this_min)\n",
    "\n",
    "            # randomly cycle the file\n",
    "            i = np.random.randint(sample.shape[1])\n",
    "            sample = torch.cat([\n",
    "                sample[:, i:, :],\n",
    "                sample[:, :i, :]],\n",
    "                dim=1)\n",
    "\n",
    "            # apply albumentations transforms\n",
    "            sample = np.array(self.pil(sample))\n",
    "            sample = self.transform(image=sample)\n",
    "            sample = sample['image']\n",
    "            sample = sample[None, :, :].permute(0, 2, 1)\n",
    "\n",
    "            # apply random erasing\n",
    "            sample = random_erasing(sample.clone().detach())\n",
    "\n",
    "            # revert min-max transformation\n",
    "            sample = (sample * (this_max - this_min)) + this_min\n",
    "\n",
    "        return sample, self.y[idx, ...], self.weights[idx, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "papermill": {
     "duration": 0.058864,
     "end_time": "2019-10-20T14:11:08.427075",
     "exception": false,
     "start_time": "2019-10-20T14:11:08.368211",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load and prepare data\n",
    "with open('../../data/metadata.pkl', 'rb') as f:\n",
    "    metadata = pickle.load(f)\n",
    "\n",
    "unknown_to_known = (\n",
    "    pd.merge(metadata['taxonomy_df'].loc[lambda x: x.fine_id == 'X', ['fine', 'coarse']],\n",
    "             metadata['taxonomy_df'].loc[lambda x: x.fine_id != 'X', ['fine', 'coarse']],\n",
    "             on='coarse', how='inner')\n",
    "    .drop(columns='coarse')\n",
    "    .groupby('fine_x')['fine_y']\n",
    "    .apply(lambda x: list(x)).to_dict())\n",
    "known_labels = metadata['taxonomy_df'].loc[lambda x: x.fine_id != 'X'].fine.tolist()\n",
    "\n",
    "train_df = pd.concat([metadata['coarse_train'], metadata['fine_train']], axis=1, sort=True)\n",
    "valid_df = pd.concat([metadata['coarse_test'], metadata['fine_test']], axis=1, sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "papermill": {
     "duration": 0.064601,
     "end_time": "2019-10-20T14:11:08.514689",
     "exception": false,
     "start_time": "2019-10-20T14:11:08.450088",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# manual correction for one data point\n",
    "train_df.loc[(train_df.sum(axis=1) == 37).copy(), :] = 0\n",
    "valid_df.loc[(valid_df.sum(axis=1) == 37).copy(), :] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "papermill": {
     "duration": 3.619916,
     "end_time": "2019-10-20T14:11:12.157793",
     "exception": false,
     "start_time": "2019-10-20T14:11:08.537877",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_X, train_y, train_y_mask = prepare_data(train_df, unknown_to_known)\n",
    "valid_X, valid_y, valid_y_mask = prepare_data(valid_df, unknown_to_known)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "papermill": {
     "duration": 6.549724,
     "end_time": "2019-10-20T14:11:18.720379",
     "exception": false,
     "start_time": "2019-10-20T14:11:12.170655",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Channel wise normalization\n",
    "channel_means = train_X.reshape(-1, 128).mean(axis=0).reshape(1, 1, 1, -1)\n",
    "channel_stds = train_X.reshape(-1, 128).std(axis=0).reshape(1, 1, 1, -1)\n",
    "train_X = (train_X - channel_means) / channel_stds\n",
    "valid_X = (valid_X - channel_means) / channel_stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "papermill": {
     "duration": 0.032893,
     "end_time": "2019-10-20T14:11:18.777374",
     "exception": false,
     "start_time": "2019-10-20T14:11:18.744481",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the data augmentation transformations\n",
    "albumentations_transform = Compose([\n",
    "    ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=0.5),\n",
    "    GridDistortion(),\n",
    "    ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "papermill": {
     "duration": 0.926351,
     "end_time": "2019-10-20T14:11:19.725311",
     "exception": false,
     "start_time": "2019-10-20T14:11:18.798960",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the datasets and the dataloaders\n",
    "train_dataset = AudioDataset(torch.Tensor(train_X),\n",
    "                             torch.Tensor(train_y),\n",
    "                             torch.Tensor(train_y_mask),\n",
    "                             albumentations_transform)\n",
    "valid_dataset = AudioDataset(torch.Tensor(valid_X),\n",
    "                             torch.Tensor(valid_y),\n",
    "                             torch.Tensor(valid_y_mask),\n",
    "                             None)\n",
    "\n",
    "val_loader = DataLoader(valid_dataset, 64, shuffle=False)\n",
    "train_loader_1 = DataLoader(train_dataset, 64, shuffle=True)\n",
    "train_loader_2 = DataLoader(train_dataset, 64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "papermill": {
     "duration": 0.026666,
     "end_time": "2019-10-20T14:11:19.768233",
     "exception": false,
     "start_time": "2019-10-20T14:11:19.741567",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Define the device to be used\n",
    "cuda = True\n",
    "device = torch.device('cuda:0' if cuda else 'cpu')\n",
    "print('Device: ', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "papermill": {
     "duration": 0.032653,
     "end_time": "2019-10-20T14:11:19.825680",
     "exception": false,
     "start_time": "2019-10-20T14:11:19.793027",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def weight_reset(layer):\n",
    "    if hasattr(layer, 'reset_parameters'):\n",
    "        layer.reset_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "papermill": {
     "duration": 0.040357,
     "end_time": "2019-10-20T14:11:19.890680",
     "exception": false,
     "start_time": "2019-10-20T14:11:19.850323",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Task5Model(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.bw2col = nn.Sequential(\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.Conv2d(1, 10, 1, padding=0), nn.ReLU(),\n",
    "            nn.Conv2d(10, 3, 1, padding=0), nn.ReLU())\n",
    "\n",
    "        self.mv2 = torchvision.models.mobilenet_v2(pretrained=True)\n",
    "\n",
    "        self.final = nn.Sequential(\n",
    "            nn.Linear(1280, 512), nn.ReLU(), nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, num_classes))\n",
    "        \n",
    "        # Reset after ith layer of mv2\n",
    "        for i, x in enumerate(self.mv2.features.children()):\n",
    "            if i > until_x:\n",
    "                x.apply(weight_reset)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.bw2col(x)\n",
    "        x = self.mv2.features(x)\n",
    "        x = x.max(dim=-1)[0].max(dim=-1)[0]\n",
    "        x = self.final(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "papermill": {
     "duration": 4.862604,
     "end_time": "2019-10-20T14:11:24.777313",
     "exception": false,
     "start_time": "2019-10-20T14:11:19.914709",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "model = Task5Model(31).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "papermill": {
     "duration": 0.025594,
     "end_time": "2019-10-20T14:11:24.813594",
     "exception": false,
     "start_time": "2019-10-20T14:11:24.788000",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define optimizer, scheduler and loss criteria\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, amsgrad=True)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, verbose=True)\n",
    "criterion = nn.BCEWithLogitsLoss(reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "papermill": {
     "duration": 2326.249998,
     "end_time": "2019-10-20T14:50:11.087426",
     "exception": false,
     "start_time": "2019-10-20T14:11:24.837428",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6143959438478624 0.5405417425291879\n",
      "Epoch:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29252703528146484 0.22170924076012202\n",
      "Epoch:  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19162765950769992 0.17393408715724945\n",
      "Epoch:  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18378116391800545 0.17138620572430746\n",
      "Epoch:  4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1824167302331409 0.17299721283572062\n",
      "Epoch:  5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18071387990100965 0.24163648911884852\n",
      "Epoch:  6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17922056083743637 0.16660494889531816\n",
      "Epoch:  7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1758134135523358 0.17091019877365657\n",
      "Epoch:  8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1711489340743503 0.1616506746837071\n",
      "Epoch:  9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1699258729412749 0.15156027248927526\n",
      "Epoch:  10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16626419851908814 0.15011500035013473\n",
      "Epoch:  11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16459337118509654 0.1482613640172141\n",
      "Epoch:  12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1636958182663531 0.14698434514658792\n",
      "Epoch:  13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1614828786334476 0.14266929349728993\n",
      "Epoch:  14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.161990071470673 0.15182717783110483\n",
      "Epoch:  15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1621344109644761 0.14058079570531845\n",
      "Epoch:  16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1627172412904533 0.1491543778351375\n",
      "Epoch:  17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16139417927007418 0.13747635270868028\n",
      "Epoch:  18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15939349942916148 0.14175168105534144\n",
      "Epoch:  19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1598122840797579 0.13728406067405427\n",
      "Epoch:  20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15769659304941022 0.13779424343790328\n",
      "Epoch:  21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15779775421361666 0.14089846078838622\n",
      "Epoch:  22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1574798145809689 0.13326510254825866\n",
      "Epoch:  23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15598918054554914 0.13733615513358796\n",
      "Epoch:  24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15656980872154236 0.13415117348943437\n",
      "Epoch:  25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15536245945337657 0.13272906414100102\n",
      "Epoch:  26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15552916760380203 0.13156864047050476\n",
      "Epoch:  27\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1540612658938846 0.13186100125312805\n",
      "Epoch:  28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1540585784493266 0.1317261021052088\n",
      "Epoch:  29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15501877383605853 0.13717056597982133\n",
      "Epoch:  30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15495259657099442 0.13180775195360184\n",
      "Epoch:  31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15476916448490038 0.12906659500939505\n",
      "Epoch:  32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15404442476259694 0.13172664919069835\n",
      "Epoch:  33\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15274022318221428 0.12841368785926274\n",
      "Epoch:  34\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15282539419225744 0.12976826620953424\n",
      "Epoch:  35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15267997778750755 0.1290107529078211\n",
      "Epoch:  36\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15265775854523117 0.132132993212768\n",
      "Epoch:  37\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.152769344481262 0.1319166858281408\n",
      "Epoch:  38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15091426952465162 0.12871678918600082\n",
      "Epoch:  39\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15109409714067304 0.12924637539046152\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:  40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1503661278937314 0.12500238631452834\n",
      "Epoch:  41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1487866950196189 0.12495628850800651\n",
      "Epoch:  42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14955347615319328 0.12447464359658104\n",
      "Epoch:  43\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14844396347935135 0.12456234438078743\n",
      "Epoch:  44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14907437804582957 0.12451310668672834\n",
      "Epoch:  45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14907671833360517 0.12428454841886248\n",
      "Epoch:  46\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1474186612947567 0.12414603573935372\n",
      "Epoch:  47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1478209596227955 0.1244799771479198\n",
      "Epoch:  48\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1480408451847128 0.12384388808693204\n",
      "Epoch:  49\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14826355391257517 0.12405270550932203\n",
      "Epoch:  50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14855976886040456 0.12351925245353154\n",
      "Epoch:  51\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1483308797752535 0.12360283945287977\n",
      "Epoch:  52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14768722774209203 0.12362595008952278\n",
      "Epoch:  53\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1481416885917251 0.12390084138938359\n",
      "Epoch:  54\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1476245305022678 0.12442619992153985\n",
      "Epoch:  55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14689515812976942 0.12351344845124654\n",
      "Epoch:  56\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1492984254617949 0.12402345559426717\n",
      "Epoch    56: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:  57\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14798926944668228 0.12371817231178284\n",
      "Epoch:  58\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14882505302493637 0.12356592395475932\n",
      "Epoch:  59\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14766044914722443 0.12343272353921618\n",
      "Epoch:  60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14772430062294006 0.12367921109710421\n",
      "Epoch:  61\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14763760647258242 0.12377611441271645\n",
      "Epoch:  62\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14689264547180486 0.12378945095198494\n",
      "Epoch:  63\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14804649353027344 0.12347602418490819\n",
      "Epoch:  64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1483887144037195 0.123440220952034\n",
      "Epoch:  65\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14673296785032428 0.12344703397580556\n",
      "Epoch    65: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:  66\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14802812442586227 0.12380470548357282\n",
      "Epoch:  67\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14771411145055616 0.12344702226775033\n",
      "Epoch:  68\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1469296386113038 0.12356262654066086\n",
      "Epoch:  69\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1468121812150285 0.12361151937927518\n",
      "Epoch:  70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1467033032629941 0.1233245890055384\n",
      "Epoch:  71\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14695717555445595 0.12359791994094849\n",
      "Epoch:  72\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14794936695614377 0.12339210510253906\n",
      "Epoch:  73\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1468605511897319 0.12355030647345952\n",
      "Epoch:  74\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14628014814209295 0.12353531590529851\n",
      "Epoch:  75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14736629619791702 0.12340502334492547\n",
      "Epoch:  76\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1459254231807348 0.12338778589453016\n",
      "Epoch    76: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:  77\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14778513400941282 0.12336435807602746\n",
      "Epoch:  78\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14702403988387133 0.12336234109742301\n",
      "Epoch:  79\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14627269997790054 0.12330232454197747\n",
      "Epoch:  80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14618776859463872 0.12359768152236938\n",
      "Epoch:  81\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1466489184547115 0.12359587848186493\n",
      "Epoch:  82\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14712393163023768 0.1234861548457827\n",
      "Epoch:  83\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1485896879756773 0.12365025814090456\n",
      "Epoch:  84\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1469130314685203 0.12354277393647603\n",
      "Epoch:  85\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14719268719892245 0.12347685758556638\n",
      "Epoch    85: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:  86\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14679791999829783 0.12346932824168887\n",
      "Epoch:  87\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14802259408138893 0.12338808711086001\n",
      "Epoch:  88\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14853436238056905 0.12342308248792376\n",
      "Epoch:  89\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14666608016233187 0.12344626230852944\n",
      "Epoch:  90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14693200507679502 0.12324136814900807\n",
      "Epoch:  91\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14687074277852033 0.12350174252476011\n",
      "Epoch:  92\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1476056833524962 0.1236555767910821\n",
      "Epoch:  93\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14656365441309438 0.12352591007947922\n",
      "Epoch:  94\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14690446330083384 0.12334881510053362\n",
      "Epoch:  95\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1474037883249489 0.1233411974140576\n",
      "Epoch:  96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1469948984481193 0.12348777800798416\n",
      "Epoch:  97\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14816978211338455 0.12361000265393939\n",
      "Epoch:  98\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14663643369803558 0.12370048889092036\n",
      "Epoch:  99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14667375466308077 0.12360255633081708\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "train_loss_hist = []\n",
    "valid_loss_hist = []\n",
    "lowest_val_loss = np.inf\n",
    "epochs_without_new_lowest = 0\n",
    "\n",
    "for i in range(epochs):\n",
    "    print('Epoch: ', i)\n",
    "\n",
    "    this_epoch_train_loss = 0\n",
    "    for i1, i2 in zip(train_loader_1, train_loader_2):\n",
    "\n",
    "        # mixup the inputs ---------\n",
    "        alpha = 1\n",
    "        mixup_vals = np.random.beta(alpha, alpha, i1[0].shape[0])\n",
    "\n",
    "        lam = torch.Tensor(mixup_vals.reshape(mixup_vals.shape[0], 1, 1, 1))\n",
    "        inputs = (lam * i1[0]) + ((1 - lam) * i2[0])\n",
    "\n",
    "        lam = torch.Tensor(mixup_vals.reshape(mixup_vals.shape[0], 1, 1))\n",
    "        labels = (lam * i1[1]) + ((1 - lam) * i2[1])\n",
    "        masks = (lam * i1[2]) + ((1 - lam) * i2[2])\n",
    "        # mixup ends ----------\n",
    "\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        masks = masks.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        with torch.set_grad_enabled(True):\n",
    "            model = model.train()\n",
    "            outputs = model(inputs)\n",
    "            # calculate loss for each set of annotations\n",
    "            loss_0 = criterion(outputs, labels[:, :, 0]) * masks[:, :, 0]\n",
    "            loss_1 = criterion(outputs, labels[:, :, 1]) * masks[:, :, 1]\n",
    "            loss_2 = criterion(outputs, labels[:, :, 2]) * masks[:, :, 2]\n",
    "            loss = (loss_0.sum() + loss_1.sum() + loss_2.sum()) / masks.sum()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            this_epoch_train_loss += loss.detach().cpu().numpy()\n",
    "\n",
    "    this_epoch_valid_loss = 0\n",
    "    for inputs, labels, masks in val_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        masks = masks.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        with torch.set_grad_enabled(False):\n",
    "            model = model.eval()\n",
    "            outputs = model(inputs)\n",
    "            loss_0 = criterion(outputs, labels[:, :, 0]) * masks[:, :, 0]\n",
    "            loss_1 = criterion(outputs, labels[:, :, 1]) * masks[:, :, 1]\n",
    "            loss_2 = criterion(outputs, labels[:, :, 2]) * masks[:, :, 2]\n",
    "            loss = (loss_0.sum() + loss_1.sum() + loss_2.sum()) / masks.sum()\n",
    "            this_epoch_valid_loss += loss.detach().cpu().numpy()\n",
    "\n",
    "    this_epoch_train_loss /= len(train_loader_1)\n",
    "    this_epoch_valid_loss /= len(val_loader)\n",
    "\n",
    "    train_loss_hist.append(this_epoch_train_loss)\n",
    "    valid_loss_hist.append(this_epoch_valid_loss)\n",
    "\n",
    "    if this_epoch_valid_loss < lowest_val_loss:\n",
    "        lowest_val_loss = this_epoch_valid_loss\n",
    "        torch.save(model.state_dict(), './model_system1_until_{}'.format(until_x))\n",
    "        epochs_without_new_lowest = 0\n",
    "    else:\n",
    "        epochs_without_new_lowest += 1\n",
    "\n",
    "    if epochs_without_new_lowest >= 25:\n",
    "        break\n",
    "\n",
    "    print(this_epoch_train_loss, this_epoch_valid_loss)\n",
    "\n",
    "    scheduler.step(this_epoch_valid_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.060595,
     "end_time": "2019-10-20T14:50:11.229987",
     "exception": false,
     "start_time": "2019-10-20T14:50:11.169392",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "papermill": {
   "duration": 2346.601035,
   "end_time": "2019-10-20T14:50:12.594894",
   "environment_variables": {},
   "exception": null,
   "input_path": "model1-until-x-rev.ipynb",
   "output_path": "model1-until-6-rev.ipynb",
   "parameters": {
    "until_x": 6
   },
   "start_time": "2019-10-20T14:11:05.993859",
   "version": "1.2.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}